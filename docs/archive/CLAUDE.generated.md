# CLAUDE.md (Archived)
*Archived snapshot (moved 2026-02-06). For up-to-date instructions, use `AGENTS.md` and `docs/AGENTS.md`.*

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Full-stack Retrieval-Augmented Generation (RAG) application running on Cloudflare Workers. Single Worker deployment serves both React UI (built to `./public`) and Hono-based API, eliminating CORS issues and providing unified observability.

**Stack**: Cloudflare Workers + Hono + React 18 + TypeScript (strict mode) + Tailwind CSS
**AI Models**: `@cf/baai/bge-base-en-v1.5` (embeddings), `@cf/meta/llama-3.1-8b-instruct` (generation)
**Storage**: R2 (articles) + D1 (chunks/metadata) + Vectorize (embeddings) + KV (cache)

## Essential Commands

### Development
```bash
# Terminal 1: Start Worker (port 8787)
npm run dev

# Terminal 2: Start React UI with HMR (port 3000, proxies /api/* to 8787)
npm run ui:dev

# Build React to ./public (required before deployment)
npm run build
```

### Testing
```bash
npm test                # Run backend tests with Vitest
npm run test:coverage   # Generate coverage reports
cd ui && npm run lint   # Lint frontend code
```

### Database Operations
```bash
npm run db:migrate                      # Apply migrations locally
npm run db:migrate:remote               # Apply to production
npm run db:create-migration <name>      # Create new migration file
wrangler d1 migrations list wikipedia-db # View migration history
```

### Deployment
```bash
npm run deploy  # Build UI + apply migrations + deploy to production
wrangler tail --env production  # View live Worker logs
```

### Data Ingestion
```bash
python scripts/fetch-wikipedia.py --size-mb 10  # Download Wikipedia articles
npm run ingest ./data/wikipedia                 # Upload via Workflow API
```

### Type Generation
```bash
npm run cf-typegen  # Generate Cloudflare binding types
```

## Architecture Essentials

### Development Model: Two-Server Coordination

**Port 8787 (Wrangler)**: Worker + bindings (D1/Vectorize/R2/AI)
**Port 3000 (Vite)**: React dev server with `/api/*` proxy to 8787
**Important**: Vectorize, D1, R2, and AI use **remote** Cloudflare resources even in local dev (no local mode). Only KV runs locally.

### Production Model: Single Worker

Both frontend (static assets from `./public`) and API routes run in one Worker. No CORS, no separate deployments, unified logs.

### Core RAG Flow

```
User Query → Embed (BGE) → Vectorize Search → D1 Chunk Fetch → Context Assembly → LLM Generation (Llama 3.1) → Answer + Citations
```

Implementation: `src/patterns/basic-rag.ts`

### Ingestion Pipeline (Durable Workflow)

```
Article → R2 Storage → D1 Metadata → Chunking (500 chars/100 overlap) → D1 Chunks → Batch Embeddings (size 10) → Vectorize Upsert
```

Implementation: `src/ingestion-workflow.ts`

## Directory Structure Significance

```
src/
├── index.ts                      # Main Hono app (routes: /api/v1/query, /api/v1/ingest)
├── ingestion-workflow.ts         # Durable workflow for data ingestion
├── patterns/basic-rag.ts         # Single-turn RAG implementation
├── utils/
│   ├── document-store.ts         # R2/D1/Vectorize abstraction layer
│   ├── logger.ts                 # Structured logging with performance timers
│   ├── chunking.ts               # RecursiveCharacterTextSplitter wrapper
│   ├── chat-logger.ts            # D1 chat logging with IP hashing
│   ├── metadata.ts               # Cloudflare metadata extraction
│   ├── privacy.ts                # IP salting utilities
│   └── rate-limiter.ts           # Ratelimit binding wrapper
└── types/index.ts                # Central TypeScript definitions

ui/src/
├── components/
│   ├── QueryInterface.tsx        # Main chat interface component
│   ├── ChatInput.tsx             # Input with submission handling
│   ├── MessageBubble.tsx         # Message display component
│   ├── SourcesCard.tsx           # Source citations display
│   └── layouts/DemoLayout.tsx    # Main layout wrapper
├── pages/BasicChatPage.tsx       # Primary demo page
└── config.ts                     # API configuration (relative paths)

migrations/
├── 0001_create_documents_table.sql
├── 0002_create_chunks_table.sql
├── 0003_create_fts_table.sql
└── 0004_add_chat_logging.sql

public/                           # Built React app (generated by npm run build)
```

## Key Configuration Files

### wrangler.jsonc
- **Main entry**: `src/index.ts`
- **Assets**: Serves `./public` directory (React build output)
- **Bindings**:
  - `DATABASE`: D1 (documents, chunks, FTS5 indexes)
  - `VECTOR_INDEX`: Vectorize (768-dim BGE embeddings)
  - `ARTICLES_BUCKET`: R2 (full articles)
  - `EMBEDDINGS_CACHE`, `RAG_CACHE`: KV namespaces
  - `INGESTION_WORKFLOW`: WorkflowBinding
  - `AI`: Workers AI binding
  - `QUERY_LIMITER`, `INGEST_LIMITER`: Rate limiting
- **Environment variables**:
  - `LOG_LEVEL`: DEBUG/INFO/WARN/ERROR
  - `DEFAULT_CHUNK_SIZE`: 500
  - `DEFAULT_CHUNK_OVERLAP`: 100
  - `DEFAULT_TOP_K`: 3
  - `MAX_QUERY_LENGTH`: 500
  - `CHAT_LOGGING_ENABLED`: true/false
- **Secrets** (set via `wrangler secret put`):
  - `CHAT_LOG_IP_SALT`: Secure salt for IP hashing

### ui/vite.config.ts
- **Dev server**: Port 3000
- **Proxy**: `/api/*` → `http://localhost:8787`
- **Build output**: `../public` (Worker's static assets directory)

### tsconfig.json (Backend)
- **Target**: ES2022
- **Strict mode**: Enabled with `noUncheckedIndexedAccess`, `noImplicitOverride`
- **Path aliases**: `@/*`, `@/types`, `@/utils/*`, `@/patterns/*`
- **JSX**: `jsxImportSource: "hono/jsx"`

## Important Patterns & Conventions

### Storage Architecture

**R2**: Full article documents (`articles/{articleId}.json`)
**D1**: Metadata (`documents` table), chunks (`chunks` table), FTS5 index (`chunks_fts`)
**Vectorize**: 768-dimensional embeddings with metadata (`{ documentId, chunkId, chunkIndex, title }`)
**KV**: Embeddings cache (24h TTL) and RAG results cache (1h TTL)

### RAG Query Processing (src/patterns/basic-rag.ts)

1. **Validate** question length ≤ `MAX_QUERY_LENGTH`
2. **Embed** question using BGE model (cache in KV)
3. **Search** Vectorize for top-K similar chunks (default K=3)
4. **Fetch** chunk text from D1 via document-store
5. **Build** numbered context: `[1] text`, `[2] text`, etc.
6. **Generate** answer with Llama 3.1 (temperature 0.2, max_tokens 1024)
7. **Format** response with citations and similarity scores

**System prompt**: Strictly constrains LLM to context, requires citations, forbids hallucination

### Chunking Strategy (src/utils/chunking.ts)

- **Method**: `RecursiveCharacterTextSplitter` from `@langchain/textsplitters`
- **Defaults**: 500 chars/chunk, 100 char overlap (20%)
- **Separators**: `\n\n\n` → `\n\n` → `\n` → `. ` → ` `
- **Metadata**: Enriched with section headers, table/list flags, chunk position

### Logging & Observability (src/utils/logger.ts)

- **Structured logging** with context propagation
- **Performance timers**: `logger.startTimer()` / `logger.endTimer()`
- **Child loggers**: `logger.child({ requestId })` for request-scoped context
- **Log levels**: DEBUG, INFO, WARN, ERROR

### Chat Logging (src/utils/chat-logger.ts)

- **Tables**: `chat_sessions`, `chat_messages`, `chat_chunks` (created by migration 0004)
- **Privacy**: IPs hashed with `CHAT_LOG_IP_SALT` via `saltedHash()`
- **Metadata**: Captures Cloudflare request metadata (colo, country, ray ID)
- **Non-fatal**: Logging failures logged but don't break requests

### API Endpoints (src/index.ts)

- `GET /api/v1/query?q=<question>&topK=3&minSimilarity=0.7`
- `POST /api/v1/query` (JSON body: `{ question, topK?, minSimilarity? }`)
- `POST /api/v1/ingest` (JSON body: `{ title, content, metadata? }`)
- `GET /api/v1/ingest/:workflowId` (check workflow status)
- `GET /health` (Worker diagnostics)
- `GET /api/v1/docs` (API documentation)

## Development Workflow Gotchas

### Local Development Dependencies

- **Remote-only bindings**: Vectorize, D1, R2, and AI require active Cloudflare resources even in local dev
- **No local Vectorize**: Cannot test vector queries purely offline
- **D1 migrations**: Must be applied to both local (`--local`) and production (`--remote`) databases independently

### Build Process

1. **UI build** (`npm run build`): Compiles React to `./public` (static assets)
2. **Worker deployment** (`wrangler deploy`): Bundles TypeScript from `src/index.ts`, includes `./public` as static assets
3. **Single command** (`npm run deploy`): Runs UI build + migrations + deployment

### Data Ingestion Requirements

- **Worker must be running**: Ingestion script POSTs to `/api/v1/ingest` endpoint
- **Batch processing**: Script batches articles with delay to avoid rate limits
- **Workflow observability**: Check status via `/api/v1/ingest/:workflowId`

### TypeScript Strictness

- **`noUncheckedIndexedAccess`**: All array/object accesses may be `undefined`
- **Path aliases**: Use `@/utils/logger` not `../utils/logger`
- **Type imports**: Prefer `import type { Env } from '@/types'`

## Testing Strategy

### Backend Tests (Vitest)

- **Test runner**: Vitest with `@cloudflare/vitest-pool-workers`
- **Command**: `npm test`
- **Bindings**: Tests run with mocked Cloudflare bindings
- **Coverage**: `npm run test:coverage`

### Frontend Tests

- **Linting**: `cd ui && npm run lint` (ESLint with React hooks rules)
- **E2E**: Playwright available (`@playwright/test@1.57.0`)

## Migration Guidelines

### Creating Migrations

1. **Create**: `npm run db:create-migration <descriptive_name>`
2. **Edit**: Write SQL in `migrations/XXXX_<name>.sql`
3. **Apply locally**: `npm run db:migrate`
4. **Test**: Verify schema changes work with local Worker
5. **Apply remotely**: `npm run db:migrate:remote`
6. **Deploy**: `npm run deploy` (includes migration step)

### Schema Conventions

- **Primary keys**: TEXT UUIDs (e.g., `id TEXT PRIMARY KEY`)
- **Timestamps**: INTEGER (Unix epoch milliseconds)
- **Foreign keys**: Explicit `FOREIGN KEY` constraints
- **Indexes**: Prefix with `idx_` (e.g., `idx_chunks_document_id`)
- **FTS5**: Use `chunks_fts` virtual table for full-text search

## Security Considerations

### Input Validation

- **Question length**: Capped at `MAX_QUERY_LENGTH` (default 500)
- **Sanitization**: User inputs validated before processing
- **Rate limiting**: Configured via Ratelimit binding (100 queries/min, 10 ingests/min)

### Prompt Injection Prevention

- **System prompt**: Explicitly constrains LLM to context-only answers
- **Citation requirement**: LLM must reference sources with `[1]`, `[2]` notation
- **Guard mode**: Returns "not enough information" when retrieval empty

### Privacy

- **IP hashing**: Chat logs use salted SHA-256 hashes of IPs (never store raw IPs)
- **Salt management**: `CHAT_LOG_IP_SALT` secret set via `wrangler secret put`

## Performance Optimization Patterns

### Caching Strategy

**Embeddings cache** (KV): Hash of query text → 768-dim vector (24h TTL)
**Query result cache** (KV): Pattern + hash of question → full RAG response (1h TTL)

### Batch Operations

```typescript
// Batch D1 queries
const placeholders = ids.map(() => '?').join(',');
await db.prepare(`SELECT * FROM chunks WHERE id IN (${placeholders})`).bind(...ids).all();

// Batch embedding generation
await AI.run(model, { text: chunkTexts }); // Not: loop with single texts
```

### Parallel Execution

```typescript
const [embedding, metadata] = await Promise.all([
  generateEmbedding(question),
  fetchDocumentMetadata(docId)
]);
```

## Environment Variables Reference

### wrangler.jsonc Variables

- `LOG_LEVEL`: DEBUG, INFO, WARN, ERROR (default: INFO)
- `DEFAULT_CHUNK_SIZE`: Characters per chunk (default: 500)
- `DEFAULT_CHUNK_OVERLAP`: Overlap between chunks (default: 100)
- `DEFAULT_TOP_K`: Number of chunks to retrieve (default: 3)
- `MAX_QUERY_LENGTH`: Max question length (default: 500)
- `CHAT_LOGGING_ENABLED`: Enable D1 chat logging (default: true)
- `ENABLE_TEXT_SPLITTING`: Enable chunking during ingestion (default: true)

### Secrets (via `wrangler secret put`)

- `CHAT_LOG_IP_SALT`: Secure random string for IP hashing

## Deployment Best Practices

### Pre-Deployment Checklist

1. **UI build**: `npm run build` (verify `./public` populated)
2. **Type check**: `npm run cf-typegen` (no TypeScript errors)
3. **Tests**: `npm test` (all passing)
4. **Migrations**: Review pending migrations in `migrations/`
5. **Secrets**: Verify `CHAT_LOG_IP_SALT` set in production

### Production Deployment

```bash
npm run deploy  # Automated: build + migrations + deploy
```

**Manual steps** (if needed):
```bash
npm run build                                    # Build UI
wrangler d1 migrations apply wikipedia-db --remote # Apply migrations
wrangler deploy --env production                 # Deploy Worker
```

### Post-Deployment Verification

1. **Health check**: `curl https://cloudflare-rag-demo.stevenleve.com/health`
2. **Query test**: `curl "https://cloudflare-rag-demo.stevenleve.com/api/v1/query?q=test"`
3. **Logs**: `wrangler tail --env production` (watch for errors)
4. **Ingestion**: Test workflow with sample article

## Frontend Configuration (ui/src/config.ts)

- **API URL**: Uses relative paths (`/api/v1/...`) for same-origin requests
- **Dev mode**: Vite proxy handles `/api/*` → `localhost:8787`
- **Production**: Same Worker serves both UI and API (no CORS)

## Common Tasks

### Adding a New RAG Pattern

1. Create `src/patterns/new-pattern.ts` with exported function
2. Define request/response types in `src/types/index.ts`
3. Add route in `src/index.ts` (e.g., `/api/v1/patterns/new-pattern`)
4. Implement pattern logic using `document-store` and `logger` utilities
5. Add tests in `tests/patterns/new-pattern.test.ts`

### Modifying Chunking Strategy

1. Edit `src/utils/chunking.ts` (update `RecursiveCharacterTextSplitter` config)
2. Update `DEFAULT_CHUNK_SIZE` and `DEFAULT_CHUNK_OVERLAP` in `wrangler.jsonc`
3. Re-ingest data (old chunks remain until re-ingested)

### Adding New Cloudflare Binding

1. Create resource via `wrangler` CLI (e.g., `wrangler kv namespace create NEW_KV`)
2. Add binding to `wrangler.jsonc` under appropriate section
3. Update `Env` interface in `src/types/index.ts`
4. Run `npm run cf-typegen` to regenerate types

## Additional Documentation

- **Architecture deep-dive**: `docs/ARCHITECTURE.md`
- **Deployment guide**: `docs/DEPLOYMENT.md`
- **Quick start**: `docs/QUICKSTART.md`
- **Project status**: `docs/PROJECT_STATUS.md`
- **Data preparation**: `data/wikipedia/README.md`
- **Main README**: `README.md`
